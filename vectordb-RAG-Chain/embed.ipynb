{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241cc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jatin\\Desktop\\RAG-chromadb\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "##locally loading our fine tuned model using Sentance Transformer module\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"../finetune/fine-tuned-model-rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc056c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Chroma DB from langchain and Document for \n",
    "from langchain_chroma import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "\n",
    "# Load and format data\n",
    "df = pd.read_csv(\"../data_cleaning/quotes.csv\")\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "#This is here to format the documents/the text we are going to embedd in vector db so that our fine tuned model can get a better context\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=f'{row[\"quote\"]} ‚Äî {row[\"author\"]} | Tags: {\", \".join(eval(row[\"tags\"]))}',\n",
    "        metadata={\n",
    "            \"author\": row[\"author\"],\n",
    "            \"tags\": \", \".join(eval(row[\"tags\"]))  # üîß CONVERT LIST TO STRING HERE\n",
    "        }\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# some deprevation warning were being shown because the frequent changes in langchain library\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"../finetune/fine-tuned-model-rag\"\n",
    ")\n",
    "\n",
    "# Store our formated documents using our own embedding model in ChromaDB (looks like we are in full control here)\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"../Chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ed58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äúwe believe in ordinary acts of bravery, in the courage that drives one person to stand up for another.‚Äù ‚Äî veronica roth, | Tags: inspirational-quotes, strength-and-courage\n",
      "‚Äúwhatever you do, you need courage. whatever course you decide upon, there is always someone to tell you that you are wrong. there are always difficulties arising that tempt you to believe your critics are right. to map out a course of action and follow it to an end requires some of the same courage that a soldier needs. peace has its victories, but it takes brave men and women to win them.‚Äù ‚Äî ralph waldo emerson | Tags: courage, inspirational\n",
      "‚Äúi wanted you to see what real courage is, instead of getting the idea that courage is a man with a gun in his hand. it's when you know you're licked before you begin, but you begin anyway and see it through no matter what.- atticus finch‚Äù ‚Äî harper lee, | Tags: atticus-finch, courage\n",
      "‚Äúlife shrinks or expands in proportion to one's courage.‚Äù ‚Äî anais nin | Tags: courage, life\n",
      "‚Äúi learned that courage was not the absence of fear, but the triumph over it. the brave man is not he who does not feel afraid, but he who conquers that fear.‚Äù ‚Äî nelson mandela | Tags: bravery, courage, fear\n",
      "‚Äúcourage is resistance to fear, mastery of fear - not absence of fear.‚Äù ‚Äî mark twain | Tags: courage\n",
      "‚Äúbe brave to stand for what you believe in even if you stand alone.‚Äù ‚Äî roy t. bennett, | Tags: belief, beliefs, believe, courage, courage-quotes, inspiration, inspirational, inspirational-quotes, inspire, inspiring, life, life-quotes, living, motivation, motivational, optimism, optimistic, positive, positive-affirmation, positive-life, positive-thinking\n",
      "‚Äúcourage isn't having the strength to go on - it is going on when you don't have strength.‚Äù ‚Äî napoleon bonaparte | Tags: courage, inspirational, strength\n",
      "‚Äúthere are so many ways to be brave in this world. sometimes bravery involves laying down your life for something bigger than yourself, or for someone else. sometimes it involves giving up everything you have ever known, or everyone you have ever loved, for the sake of something greater.but sometimes it doesn't.sometimes it is nothing more than gritting your teeth through pain, and the work of every day, the slow walk toward a better life. that is the sort of bravery i must have now.‚Äù ‚Äî veronica roth, | Tags: bravery, choices, courage, sacrifice\n",
      "‚Äúbran thought about it. 'can a man still be brave if he's afraid?''that is the only time a man can be brave,' his father told him.‚Äù ‚Äî george r.r. martin, | Tags: bravery, courage, fear\n"
     ]
    }
   ],
   "source": [
    "# Basic testing we have not used any llm yet but we can see proficiency of our trained model just by 3-4 lines of code\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\":10})\n",
    "\n",
    "results = retriever.invoke(\"quote about courage\")\n",
    "\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA    #Creating our RAG chain by integrating all we have been doing\n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain_groq import ChatGroq  #llm comes to the play\n",
    "\n",
    "# Load Groq LLM\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "#Groq's decommissioned models causes a big blunder in our project but thanks to streamlit for showing the clear error\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    model_name=\"llama3-70b-8192\",api_key= groq_api_key \n",
    ")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant that finds and recommends quotes.\n",
    "    Use only the following context (each with quote, author, and tags) to answer the question.\n",
    "    \n",
    "    Ignore all the irrelevant quotes think and reason deep before answering.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Respond with a relevant quote, the author, and any applicable tags.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Build RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd34b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Give me a quote about fear',\n",
      " 'result': \"Here's a quote about fear:\\n\"\n",
      "           '\\n'\n",
      "           '‚Äúnothing in life is to be feared, it is only to be understood. now '\n",
      "           'is the time to understand more, so that we may fear less.‚Äù ‚Äî Marie '\n",
      "           'Curie | Tags: fear, life, science, understanding'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "query = \"Give me a quote about fear\"\n",
    "response = rag_chain.invoke(query)\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Sample questions to test quote retrieval system\n",
    "sample_queries = [\n",
    "    \"Give me a quote about being yourself\",\n",
    "    \"Share a quote by Oscar Wilde about life or truth\",\n",
    "    \"Quote about mistakes and love by Marilyn Monroe\",\n",
    "    \"Tell me a funny quote about books\",\n",
    "    \"Find a quote by Bernard M. Baruch on individuality\",\n",
    "    \"Quote about treating inferiors by J.K. Rowling\"\n",
    "]\n",
    "\n",
    "# Evaluation dataset - improved to match actual context and ground truth\n",
    "eval_data = [\n",
    "    {\n",
    "        \"question\": \"Give me a quote about being yourself\",\n",
    "        \"answer\": \"Be yourself; everyone else is already taken.\",\n",
    "        \"contexts\": [\n",
    "            '\"Be yourself; everyone else is already taken.\" ‚Äî Oscar Wilde | Tags: be-yourself, honesty, inspirational'\n",
    "        ],\n",
    "        \"ground_truth\": \"Be yourself; everyone else is already taken.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Share a quote by Oscar Wilde about life or truth\",\n",
    "        \"answer\": \"To live is the rarest thing in the world. Most people exist, that is all.\",\n",
    "        \"contexts\": [\n",
    "            '\"To live is the rarest thing in the world. Most people exist, that is all.\" ‚Äî Oscar Wilde | Tags: life'\n",
    "        ],\n",
    "        \"ground_truth\": \"To live is the rarest thing in the world. Most people exist, that is all.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Quote about mistakes and love by Marilyn Monroe\",\n",
    "        \"answer\": \"If you can't handle me at my worst, then you sure as hell don't deserve me at my best.\",\n",
    "        \"contexts\": [\n",
    "            '\"I\\'m selfish, impatient and a little insecure... but if you can\\'t handle me at my worst...\" ‚Äî Marilyn Monroe | Tags: love, mistakes, life'\n",
    "        ],\n",
    "        \"ground_truth\": \"I'm selfish, impatient and a little insecure. I make mistakes... but if you can't handle me at my worst, then you sure as hell don't deserve me at my best.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Tell me a funny quote about books\",\n",
    "        \"answer\": \"So many books, so little time.\",\n",
    "        \"contexts\": [\n",
    "            '\"So many books, so little time.\" ‚Äî Frank Zappa | Tags: books, humor'\n",
    "        ],\n",
    "        \"ground_truth\": \"So many books, so little time.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find a quote by Bernard M. Baruch on individuality\",\n",
    "        \"answer\": \"Be who you are and say what you feel...\",\n",
    "        \"contexts\": [\n",
    "            '\"Be who you are and say what you feel...\" ‚Äî Bernard M. Baruch | Tags: individuality, be-yourself'\n",
    "        ],\n",
    "        \"ground_truth\": \"Be who you are and say what you feel, because those who mind don't matter, and those who matter don't mind.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Quote about treating inferiors by J.K. Rowling\",\n",
    "        \"answer\": \"If you want to know what a man's like...\",\n",
    "        \"contexts\": [\n",
    "            '\"If you want to know what a man\\'s like...\" ‚Äî J.K. Rowling | Tags: character'\n",
    "        ],\n",
    "        \"ground_truth\": \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#question: What the user asked.\n",
    "# answer: What your RAG model responded with.\n",
    "# contexts: The quote passage retrieved from your vector DB (e.g., ChromaDB).\n",
    "# ground_truth: The correct answer to compare against your model's answer.\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "ragas_dataset = Dataset.from_list(eval_data)\n",
    "\n",
    "# Dataset({\n",
    "#     features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
    "#     num_rows: 6\n",
    "# })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c5c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# LLM from Groq\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    api_key=groq_api_key\n",
    ")\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"../finetune/fine-tuned-model-rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ff289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20/24 [02:40<00:31,  7.76s/it]Exception raised in Job[0]: TimeoutError()\n",
      "Evaluating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 21/24 [03:00<00:33, 11.09s/it]Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Evaluating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23/24 [03:01<00:06,  6.57s/it]Exception raised in Job[23]: TimeoutError()\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [03:02<00:00,  7.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 1.0000, 'answer_relevancy': 0.2967, 'context_precision': 1.0000, 'context_recall': 0.7333}\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from ragas.evaluation import evaluate\n",
    "\n",
    "results = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "    llm=llm,                 # LLM from Groq\n",
    "    embeddings=embedding     # fine-tuned embedding model\n",
    ")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a17728",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(eval_data).to_csv(\"Evaluation_outputs.csv\", index=False) # Saves the output csv to our vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
